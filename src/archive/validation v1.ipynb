{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e501652b",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dba703f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76d0c2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 11)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('test1_menu.csv')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd9a9e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('test2_novelty_slider.csv')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b8af111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 12)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('test3_product_sliders.csv')\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14c8eebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 9)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv('test4_reviews.csv')\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7894cc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19000, 11)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.read_csv('test5_search_engine.csv')\n",
    "df5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b142cb1",
   "metadata": {},
   "source": [
    "#### Validation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59fcfb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare, ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141ff802",
   "metadata": {},
   "source": [
    "##### Sample Ratio Mismatch (SRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bbfc6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def srm_check(\n",
    "    df,\n",
    "    variant_col=\"variant\",\n",
    "    expected_ratio=None,\n",
    "    alpha=0.001,\n",
    "    strict=False,\n",
    "    expected_k=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Sample Ratio Mismatch (SRM) check using Chi-Square test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Data experiment\n",
    "    variant_col : str\n",
    "        Column name for variant\n",
    "    expected_ratio : list or None\n",
    "        Expected ratio per variant (e.g. [0.5, 0.5]).\n",
    "        If None → equal split assumed.\n",
    "    alpha : float\n",
    "        Significance level\n",
    "    strict : bool\n",
    "        If True → enforce expected_k\n",
    "    expected_k : int or None\n",
    "        Expected number of variants (used if strict=True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "    \"\"\"\n",
    "\n",
    "    actual_counts = df[variant_col].value_counts().sort_index()\n",
    "    actual = actual_counts.values\n",
    "    k = len(actual)\n",
    "    total = actual.sum()\n",
    "\n",
    "    # STRICT MODE\n",
    "    if strict and expected_k is not None:\n",
    "        if k != expected_k:\n",
    "            raise ValueError(\n",
    "                f\"Expected {expected_k} variants, found {k}: \"\n",
    "                f\"{list(actual_counts.index)}\"\n",
    "            )\n",
    "\n",
    "    # Expected counts\n",
    "    if expected_ratio is None:\n",
    "        expected = np.ones(k) * total / k\n",
    "    else:\n",
    "        expected_ratio = np.array(expected_ratio)\n",
    "        if len(expected_ratio) != k:\n",
    "            raise ValueError(\n",
    "                \"Length of expected_ratio must match number of variants\"\n",
    "            )\n",
    "        expected = expected_ratio * total\n",
    "\n",
    "    chi2, p_value = stats.chisquare(actual, expected)\n",
    "\n",
    "    return {\n",
    "        \"variants\": list(actual_counts.index),\n",
    "        \"actual_counts\": actual_counts.to_dict(),\n",
    "        \"expected_counts\": dict(zip(actual_counts.index, expected)),\n",
    "        \"chi2\": chi2,\n",
    "        \"p_value\": p_value,\n",
    "        \"SRM\": p_value < alpha\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52aad282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n",
      "Variants: ['A_horizontal_menu', 'B_dropdown_menu']\n",
      "p-value: 1.0\n",
      "✅ No SRM\n",
      "----------------------------------------\n",
      "Dataset 2\n",
      "Variants: ['A_manual_novelties', 'B_personalized_novelties']\n",
      "p-value: 1.0\n",
      "✅ No SRM\n",
      "----------------------------------------\n",
      "Dataset 3\n",
      "Variants: ['A_selected_by_others_only', 'B_similar_products_top', 'C_selected_by_others_top']\n",
      "p-value: 1.0\n",
      "✅ No SRM\n",
      "----------------------------------------\n",
      "Dataset 4\n",
      "Variants: ['A_no_featured_reviews', 'B_featured_reviews']\n",
      "p-value: 1.0\n",
      "✅ No SRM\n",
      "----------------------------------------\n",
      "Dataset 5\n",
      "Variants: ['A_hybris_search', 'B_algolia_search']\n",
      "p-value: 1.0\n",
      "✅ No SRM\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"Dataset 1\": df1,\n",
    "    \"Dataset 2\": df2,\n",
    "    \"Dataset 3\": df3,\n",
    "    \"Dataset 4\": df4,\n",
    "    \"Dataset 5\": df5\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    try:\n",
    "        res = srm_check(df)\n",
    "        print(f\"{name}\")\n",
    "        print(\"Variants:\", res[\"variants\"])\n",
    "        print(\"p-value:\", res[\"p_value\"])\n",
    "        print(\"❌ SRM\" if res[\"SRM\"] else \"✅ No SRM\")\n",
    "        print(\"-\" * 40)\n",
    "    except Exception as e:\n",
    "        print(f\"{name} ERROR:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51c02b6",
   "metadata": {},
   "source": [
    "##### Covariate Balance Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12d7bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardized_mean_diff(x1, x2):\n",
    "    mean_diff = x1.mean() - x2.mean()\n",
    "    pooled_std = np.sqrt((x1.var() + x2.var()) / 2)\n",
    "    return mean_diff / pooled_std if pooled_std != 0 else 0\n",
    "\n",
    "\n",
    "def covariate_balance_check(\n",
    "    df,\n",
    "    variant_col,\n",
    "    numerical_cols=None,\n",
    "    categorical_cols=None,\n",
    "    alpha=0.001\n",
    "):\n",
    "    \"\"\"\n",
    "    Covariate balance verification across variants.\n",
    "\n",
    "    Returns dict of balance results.\n",
    "    \"\"\"\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    variants = df[variant_col].unique()\n",
    "\n",
    "    # ========== NUMERICAL ==========\n",
    "    if numerical_cols:\n",
    "        num_results = {}\n",
    "\n",
    "        for col in numerical_cols:\n",
    "            smd_pairs = {}\n",
    "\n",
    "            for i in range(len(variants)):\n",
    "                for j in range(i + 1, len(variants)):\n",
    "                    v1, v2 = variants[i], variants[j]\n",
    "\n",
    "                    x1 = df[df[variant_col] == v1][col].dropna()\n",
    "                    x2 = df[df[variant_col] == v2][col].dropna()\n",
    "\n",
    "                    smd = standardized_mean_diff(x1, x2)\n",
    "\n",
    "                    smd_pairs[f\"{v1} vs {v2}\"] = {\n",
    "                        \"SMD\": smd,\n",
    "                        \"balanced\": abs(smd) < 0.1\n",
    "                    }\n",
    "\n",
    "            num_results[col] = smd_pairs\n",
    "\n",
    "        results[\"numerical\"] = num_results\n",
    "\n",
    "    # ========== CATEGORICAL ==========\n",
    "    if categorical_cols:\n",
    "        cat_results = {}\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            contingency = pd.crosstab(df[variant_col], df[col])\n",
    "            chi2, p_value, _, _ = stats.chi2_contingency(contingency)\n",
    "\n",
    "            cat_results[col] = {\n",
    "                \"p_value\": p_value,\n",
    "                \"balanced\": p_value >= alpha\n",
    "            }\n",
    "\n",
    "        results[\"categorical\"] = cat_results\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b933a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_covariates(df, variant_col, exclude_cols=None):\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "\n",
    "    exclude = set([variant_col] + exclude_cols)\n",
    "\n",
    "    numerical_cols = [\n",
    "        c for c in df.select_dtypes(include=[np.number]).columns\n",
    "        if c not in exclude\n",
    "    ]\n",
    "\n",
    "    categorical_cols = [\n",
    "        c for c in df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "        if c not in exclude\n",
    "    ]\n",
    "\n",
    "    return numerical_cols, categorical_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a1ec1943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 1\n",
      "========================================\n",
      "❌ Numerical imbalance: added_to_cart (A_horizontal_menu vs B_dropdown_menu), SMD=0.356\n",
      "❌ Numerical imbalance: revenue (A_horizontal_menu vs B_dropdown_menu), SMD=0.153\n",
      "\n",
      "Dataset 2\n",
      "========================================\n",
      "✅ All covariates balanced\n",
      "\n",
      "Dataset 3\n",
      "========================================\n",
      "❌ Numerical imbalance: revenue_from_recommendations (A_selected_by_others_only vs B_similar_products_top), SMD=-0.297\n",
      "❌ Numerical imbalance: revenue_from_recommendations (B_similar_products_top vs C_selected_by_others_top), SMD=0.222\n",
      "❌ Numerical imbalance: products_per_order (A_selected_by_others_only vs B_similar_products_top), SMD=0.129\n",
      "❌ Numerical imbalance: avg_product_price (A_selected_by_others_only vs B_similar_products_top), SMD=-0.325\n",
      "❌ Numerical imbalance: avg_product_price (A_selected_by_others_only vs C_selected_by_others_top), SMD=-0.211\n",
      "❌ Numerical imbalance: avg_product_price (B_similar_products_top vs C_selected_by_others_top), SMD=0.117\n",
      "\n",
      "Dataset 4\n",
      "========================================\n",
      "✅ All covariates balanced\n",
      "\n",
      "Dataset 5\n",
      "========================================\n",
      "✅ All covariates balanced\n"
     ]
    }
   ],
   "source": [
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    try:\n",
    "        num_cols, cat_cols = detect_covariates(\n",
    "            df,\n",
    "            variant_col=\"variant\",\n",
    "            exclude_cols=[]\n",
    "        )\n",
    "\n",
    "        imbalance_flag = False\n",
    "\n",
    "        balance = covariate_balance_check(\n",
    "            df,\n",
    "            variant_col=\"variant\",\n",
    "            numerical_cols=num_cols,\n",
    "            categorical_cols=cat_cols\n",
    "        )\n",
    "\n",
    "        # NUMERICAL\n",
    "        for col, pairs in balance.get(\"numerical\", {}).items():\n",
    "            for pair, res in pairs.items():\n",
    "                if not res[\"balanced\"]:\n",
    "                    print(f\"❌ Numerical imbalance: {col} ({pair}), SMD={res['SMD']:.3f}\")\n",
    "                    imbalance_flag = True\n",
    "\n",
    "        # CATEGORICAL\n",
    "        for col, res in balance.get(\"categorical\", {}).items():\n",
    "            if not res[\"balanced\"]:\n",
    "                print(f\"❌ Categorical imbalance: {col}, p-value={res['p_value']:.4f}\")\n",
    "                imbalance_flag = True\n",
    "\n",
    "        if not imbalance_flag:\n",
    "            print(\"✅ All covariates balanced\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipped due to error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936a215",
   "metadata": {},
   "source": [
    "##### Temporal Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38111377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_stability_check(\n",
    "    df,\n",
    "    variant_col,\n",
    "    time_col,\n",
    "    freq=\"D\",\n",
    "    alpha=0.001,\n",
    "    min_count=30\n",
    "):\n",
    "    \"\"\"\n",
    "    Temporal stability check using chi-square across time slices.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "\n",
    "    df[\"time_slice\"] = df[time_col].dt.to_period(freq)\n",
    "\n",
    "    unstable_slices = []\n",
    "\n",
    "    for ts, g in df.groupby(\"time_slice\"):\n",
    "        counts = g[variant_col].value_counts()\n",
    "\n",
    "        # skip low-volume slices\n",
    "        if counts.sum() < min_count or len(counts) < 2:\n",
    "            continue\n",
    "\n",
    "        k = len(counts)\n",
    "        expected = np.ones(k) * counts.sum() / k\n",
    "\n",
    "        chi2, p_value = stats.chisquare(counts.values, expected)\n",
    "\n",
    "        if p_value < alpha:\n",
    "            unstable_slices.append({\n",
    "                \"time_slice\": str(ts),\n",
    "                \"p_value\": p_value,\n",
    "                \"counts\": counts.to_dict()\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        \"unstable\": len(unstable_slices) > 0,\n",
    "        \"n_unstable_slices\": len(unstable_slices),\n",
    "        \"details\": unstable_slices\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e085074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_variant_col(df, max_unique=10):\n",
    "    candidates = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"O\" or pd.api.types.is_categorical_dtype(df[col]):\n",
    "            nunique = df[col].nunique(dropna=True)\n",
    "\n",
    "            if 2 <= nunique <= max_unique:\n",
    "                candidates.append(col)\n",
    "\n",
    "    if not candidates:\n",
    "        raise ValueError(\"No suitable variant column found\")\n",
    "\n",
    "    # ambil yang unique-nya paling kecil\n",
    "    return min(candidates, key=lambda c: df[c].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c00b05da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_time_col(df):\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            pd.to_datetime(df[col], errors=\"raise\")\n",
    "            return col\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    raise ValueError(\"No datetime column found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1cd934de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 1\n",
      "========================================\n",
      "✅ Temporal stable\n",
      "\n",
      "Dataset 2\n",
      "========================================\n",
      "✅ Temporal stable\n",
      "\n",
      "Dataset 3\n",
      "========================================\n",
      "✅ Temporal stable\n",
      "\n",
      "Dataset 4\n",
      "========================================\n",
      "✅ Temporal stable\n",
      "\n",
      "Dataset 5\n",
      "========================================\n",
      "✅ Temporal stable\n"
     ]
    }
   ],
   "source": [
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    try:\n",
    "        # old - variant_col = detect_variant_col(df)\n",
    "        ''' variant_col = 'variant'(df)\n",
    "        time_col = detect_time_col(df)\n",
    "\n",
    "        print(f\"Detected variant_col: {variant_col}\")\n",
    "        print(f\"Detected time_col   : {time_col}\") '''\n",
    "\n",
    "        result = temporal_stability_check(\n",
    "            df,\n",
    "            variant_col='variant',\n",
    "            time_col='timestamp',\n",
    "            freq=\"D\"\n",
    "        )\n",
    "\n",
    "        if result[\"unstable\"]:\n",
    "            print(f\"❌ Temporal instability \"\n",
    "                  f\"({result['n_unstable_slices']} slices)\")\n",
    "        else:\n",
    "            print(\"✅ Temporal stable\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipped due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565224b",
   "metadata": {},
   "source": [
    "##### Multiple Testing Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f76d7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_testing_correction(\n",
    "    p_values,\n",
    "    method=\"fdr_bh\",\n",
    "    alpha=0.001\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply multiple testing correction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p_values : dict\n",
    "        {test_name: p_value}\n",
    "    method : str\n",
    "        'bonferroni' or 'fdr_bh'\n",
    "    alpha : float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"test\": list(p_values.keys()),\n",
    "        \"p_value\": list(p_values.values())\n",
    "    }).sort_values(\"p_value\")\n",
    "\n",
    "    m = len(df)\n",
    "\n",
    "    if method == \"bonferroni\":\n",
    "        df[\"p_adj\"] = df[\"p_value\"] * m\n",
    "        df[\"significant\"] = df[\"p_adj\"] < alpha\n",
    "\n",
    "    elif method == \"fdr_bh\":\n",
    "        df[\"rank\"] = np.arange(1, m + 1)\n",
    "        df[\"p_adj\"] = df[\"p_value\"] * m / df[\"rank\"]\n",
    "        df[\"p_adj\"] = df[\"p_adj\"].clip(upper=1.0)\n",
    "        df[\"significant\"] = df[\"p_adj\"] < alpha\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'bonferroni' or 'fdr_bh'\")\n",
    "\n",
    "    return df[[\"test\", \"p_value\", \"p_adj\", \"significant\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a92b9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = {\n",
    "    \"Dataset 1\": 1.0,\n",
    "    \"Dataset 2\": 1.0,\n",
    "    \"Dataset 3\": 1.0,\n",
    "    \"Dataset 4\": 1.0,\n",
    "    \"Dataset 5\": 1.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "26421ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>p_value</th>\n",
       "      <th>p_adj</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset 2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset 3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset 4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset 5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        test  p_value  p_adj  significant\n",
       "0  Dataset 1      1.0    1.0        False\n",
       "1  Dataset 2      1.0    1.0        False\n",
       "2  Dataset 3      1.0    1.0        False\n",
       "3  Dataset 4      1.0    1.0        False\n",
       "4  Dataset 5      1.0    1.0        False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected = multiple_testing_correction(\n",
    "    p_values,\n",
    "    method=\"fdr_bh\",\n",
    "    alpha=0.001\n",
    ")\n",
    "\n",
    "corrected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e55c191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>p_value</th>\n",
       "      <th>p_adj</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset 2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset 3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset 4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset 5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        test  p_value  p_adj  significant\n",
       "0  Dataset 1      1.0    5.0        False\n",
       "1  Dataset 2      1.0    5.0        False\n",
       "2  Dataset 3      1.0    5.0        False\n",
       "3  Dataset 4      1.0    5.0        False\n",
       "4  Dataset 5      1.0    5.0        False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected = multiple_testing_correction(\n",
    "    p_values,\n",
    "    method=\"bonferroni\",\n",
    "    alpha=0.001\n",
    ")\n",
    "\n",
    "corrected\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
